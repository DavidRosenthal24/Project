# Project
David Rosenthal, Hannah Metzler, Mike Brown, James Jacobson
CSC 496 deliverable two
5/2/2020

Group Project

	For our project for CSC 496 Cloud Computing, our goal was to make a file sharing service. That is, we wanted to be able to share our files using the cloud to multiple users if need be. Although not entirely successful, this challenge can be a good learning experience for anyone who wants to get in to cloud computing. File sharing, while it sounds like a relatively basic concept, can be surprisingly difficult to figure out, and there is a lot more going on under the hood than one might think. File sharing is incredibly useful because if a business puts its files on the cloud, then they are not responsible for all the data that it contains and they are not responsible for maintaining the security of the cloud. This can take a lot of pressure off a business. Probably the most well-known file sharing system today is Google Drive. This feature is used by tons of people to store files, and gives a ton of storage completely free(granted you have the internet.) There are basically two types of file sharing services: sharing between two computers and sharing between a computer and network. Sharing between two computers is pretty straightforward, however, sharing between a computer and a server is just a touch more interesting. This is when a computer gives a file to a server, and that server holds it until one or more computers accesses it. As with many projects like this, our first thought was just to Google how to make a file sharing service with Docker and hope there was a good explanation of how to do it. Soon after you delve in, you discover there are going to be more obstacles than expected. In this paper, we will talk about deployment strategies and the basics of a file sharing service.	
	For our file sharing service, our basic idea that we started with was to try and get to Docker containers to talk or communicate with each other. Obviously, our step one was to create two docker containers and figure out a way that we could somehow connect them together so that they would be able to share with each other. We eventually reached a point where we were able to get the containers to talk to each other, however, we learned we were not doing it correctly. We were virtualizing and instead, we needed to have the containers on the same network. This was actually the host computer communicating with the Virtual Machine. We mounted a folder that was located on the main machine to the virtual machine and found a way to make them communicate. By doing this we realized that almost anything can talk to something else, you just have to figure out a way to do it. With that being said, after a lot of research we realized what we were doing wrong and how to fix it. After this, we pretty much needed to start over. 
Our next step, we had to be to figure out how to create two containers and put them on the same network and then from that point figure out what we were going to do to be able to get them to communicate. First, we needed to decide how we were going to create the containers and put them on the same network. There are multiple possible ways to do this, whether it be creating your own network using the “Docker network create” command or using one of the built-in networks from Docker. When we were trying to create our own network, however, we ended up having trouble creating the second container, as we kept getting errors. This was not the step of the project that we had hoped we would be getting errors on.
We finally realized how to create the two containers and have them communicate with one another. Once the volume is created we make containers to link to them. This puts them onto the same network and allows them to talk to one another. If we created another container and did not link them to the same volume then they would not be able to relay the message we needed it to, let alone be able to talk to each other. Now that both containers have been created and are based off an ubuntu image we write something out and save it as a .txt file and saved it out. Continuing on, we restarted the container and made sure that it was back up and functional. Upon this coming up we enter the container and run a small command line that prints out the file from the other container which tells us that it works.
	So far this project has shown a little bit about how an extremely useful tool like file sharing can be created. While there were points where there was some struggle involved, we think that if we continue at the progress we are going at, we will hopefully be able to complete the third deliverable and fulfill our groups original plan for our goal for this project. There are some things that we believe that we are missing. A real server would hold things where we can log into the IP address and control it from there. Unfortunately we have not been able to figure out how to make that actually happen, it does not seem like there is a way solid way to do this using docker toolbox. However, this does simulate the fact that as long as a container is connect to the same volume that it will be able to share files and that leads us into the next thing that would be nice to figure out. That would be getting more that one computer to be able to talk across the cloud and be able to hit the server from anywhere. This is more invasive than we have time for though because this requires an active IP address that is public and can be hit anywhere in the world. A public IP address would allow the specific server to talk across the world wide web and give us the possibility of reaching it from where ever we may be. A virtual private network would also allow for this to work, since you can connect to a VPN which is a tunnel into the home network this would also be able to work. This however becomes extremely hard to simulate, if we even can, on a cloud based system. In the end we do hope that this has hit what is needed and shows just how things like this can work. 
This project has had its up and downs, especially with everything going on in the world right now. We should have used our time better but since we are on opposite schedules we did what we could. If we could do this over again and do somethings differently, well we would. We would use our time better and meet more if we could. We learned that this was harder than we thought it would be. Even if it was not as invasive as it could have been, it still took a lot of time and energy to get this to work as is. The docker website help us out a lot and google explained it better. Not knowing was half the battle and learning what needed to be done to accomplish this was a difficult challenge but ended up being satisfying once we completed this. Overall, we could have worked better but at the end of the day we got it done together and that is all that matters.
